{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtH6GwXtY0P3yyU9KkzzXx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AchiengMary/CubeSat_Nairobi/blob/main/MobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "eAKyByt5P0du",
        "outputId": "89fa0f00-499a-4cf2-c3ed-b479ba8618bd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8336265fdecd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# One-hot encode the labels (assuming you have 5 classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Define the CNN model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential  # Importing Sequential to build the model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense  # Importing necessary layers for the CNN\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# One-hot encode the labels (assuming you have 5 classes)\n",
        "train_labels = to_categorical(train_labels, num_classes=5)\n",
        "\n",
        "# Define the CNN model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(512, 512, 3)),  # Convolutional layer + ReLU activation\n",
        "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    Conv2D(32, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
        "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    Conv2D(64, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
        "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    Conv2D(128, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
        "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    GlobalAveragePooling2D(),  # Global average pooling layer\n",
        "    Dense(5, activation='softmax')  # Output layer with 5 neurons (one for each class) + Softmax activation\n",
        "])\n",
        "\n",
        "# Compile the model with appropriate loss function, optimizer, and metrics\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model defined and compiled successfully.\")\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=10,  # Number of epochs\n",
        "    batch_size=64,  # Batch size\n",
        ")\n",
        "\n",
        "print(\"Model training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load and preprocess dataset (CIFAR-10 as an example)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize images to [0,1] range\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = 10  # Adjust if using a different dataset\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Data Augmentation for better generalization\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
        "\n",
        "# Load pre-trained MobileNetV3 without top layers\n",
        "base_model = MobileNetV3Small(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Freeze base model layers to retain pre-trained features\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom classification head\n",
        "x = GlobalAveragePooling2D()(base_model.output)  # Global pooling to reduce dimensions\n",
        "x = Dense(128, activation=\"relu\")(x)  # Fully connected layer\n",
        "x = Dropout(0.3)(x)  # Dropout to prevent overfitting\n",
        "output_layer = Dense(num_classes, activation=\"softmax\")(x)  # Output layer\n",
        "\n",
        "# Create final model\n",
        "model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model for 15 epochs\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    epochs=15,\n",
        "                    batch_size=32,\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"mobilenetv3_cifar10.h5\")\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "id": "7ynxxaBnUSR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#Load the dataset from .npy files\n",
        "x_train = np.load(\"data/train_images.npy\")\n",
        "y_train = np.load(\"data/train_labels.npy\")\n",
        "x_test = np.load(\"data/test_images.npy\")\n",
        "y_test = np.load(\"data/test_labels.npy\")\n",
        "\n",
        "#Normalize images (convert pixel values to range [0,1])\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "#Convert labels to one-hot encoding\n",
        "num_classes = len(np.unique(y_train))  # Automatically detect number of classes\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Data Augmentation for robustness\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
        "\n",
        "#Load pre-trained MobileNetV3 as a feature extractor\n",
        "base_model = MobileNetV3Small(weights=\"imagenet\", include_top=False, input_shape=x_train.shape[1:])\n",
        "\n",
        "#Freeze base model layers to retain pre-trained features\n",
        "base_model.trainable = False\n",
        "\n",
        "#Build a custom classification head\n",
        "x = GlobalAveragePooling2D()(base_model.output)  # Reduce dimensions\n",
        "x = Dense(128, activation=\"relu\")(x)  # Fully connected layer\n",
        "x = Dropout(0.3)(x)  # Prevent overfitting\n",
        "output_layer = Dense(num_classes, activation=\"softmax\")(x)  # Output layer\n",
        "\n",
        "#Create final model\n",
        "model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "#Train the model for 15 epochs\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    epochs=3,\n",
        "                    batch_size=32,\n",
        "                    verbose=1)\n",
        "\n",
        "#Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "#Save the trained model\n",
        "model.save(\"mobilenetv3_custom.h5\")\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "MDd4TSiQd21e",
        "outputId": "fffb9909-e6b6-429c-f791-53e566933a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/train_images.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-00524218bb1f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Load the dataset from .npy files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/train_images.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/train_labels.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/test_images.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train_images.npy'"
          ]
        }
      ]
    }
  ]
}