{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ed05bb-fe72-45c8-aaf4-f067ee02838e",
   "metadata": {},
   "source": [
    "# Notebook 3: Classification using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0cbf42-add7-486e-9e2d-6f04051b812e",
   "metadata": {},
   "source": [
    "In this notebook, we will use a CNN model to classify the images, following the approach used in the following [paper](https://ui.adsabs.harvard.edu/abs/2023SPIE12729E..0KC/abstract)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13095d08-82fa-49dc-8613-e8d4d1320555",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f39eb1-6f50-40c3-8468-226c0c8ee6b4",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f576c9-784f-49d2-bf5d-6978edeb89d4",
   "metadata": {},
   "source": [
    "First, we’ll load the saved image and label data from the NumPy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4a8dd1-52ed-4514-8cd1-a59980fab45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from NumPy files.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Importing NumPy for numerical operations and array handling\n",
    "\n",
    "# Load the images and labels back from the saved NumPy files\n",
    "all_images_np = np.load('all_images.npy')  # Load image data\n",
    "all_labels_np = np.load('all_labels.npy')  # Load label data\n",
    "\n",
    "print(\"Data loaded successfully from NumPy files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7067fb0-ecba-4114-9f5c-6c4ab7747562",
   "metadata": {},
   "source": [
    "#### Convert Labels to Integer Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2709e909-2d4b-4823-b51c-a09191fb3f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels converted to integer format.\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from string labels to integer labels\n",
    "label_mapping = {'Blurry': 0, 'Corrupt': 1, 'Missing_Data': 2, 'Noisy': 3, 'Priority': 4}\n",
    "\n",
    "# Convert string labels to integers using the mapping\n",
    "all_labels_np = np.array([label_mapping[label] for label in all_labels_np])\n",
    "\n",
    "print(\"Labels converted to integer format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c49214-a2a4-4e55-899f-9778270f7121",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f5d0c-6c05-4410-8a84-c6635e0085cf",
   "metadata": {},
   "source": [
    "### Step 2: Split the Data into Training and Validation Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f996f91-0951-4a8e-9742-820edb59b9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 12948 images\n",
      "Validation data: 3237 images\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  # Importing train_test_split for splitting data into training and validation sets\n",
    "\n",
    "# Split the data: 80% training, 20% validation\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    all_images_np, all_labels_np, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training data: {len(train_images)} images\")\n",
    "print(f\"Validation data: {len(val_images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953fc9a-d986-47e1-8872-213f8518cdb7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a46294-7dfd-46c0-9146-d53220c58dbb",
   "metadata": {},
   "source": [
    "### Train CubeCatNet CNN mdoel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66741a35-2b50-4d26-a964-fc6d7da017d6",
   "metadata": {},
   "source": [
    "We will define and train a Convolutional Neural Network (CNN) model that was defined in [link](https://ui.adsabs.harvard.edu/abs/2023SPIE12729E..0KC/abstract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af7dbc5a-b183-4974-a3fd-7ce74c4fa66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 14:26:53.477537: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-07 14:26:53.485774: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-07 14:26:53.502136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-07 14:26:53.524640: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-07 14:26:53.531217: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-07 14:26:53.554160: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-07 14:27:26.290786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/idia/projects/hack4dev/CubeSat_ImageClassify/vCube/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model defined and compiled successfully.\n",
      "Epoch 1/10\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 3s/step - accuracy: 0.6975 - loss: 1.2635 - val_accuracy: 0.9889 - val_loss: 0.2845\n",
      "Epoch 2/10\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m696s\u001b[0m 3s/step - accuracy: 0.9675 - loss: 0.1209 - val_accuracy: 0.9935 - val_loss: 0.2227\n",
      "Epoch 3/10\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m712s\u001b[0m 4s/step - accuracy: 0.9947 - loss: 0.0213 - val_accuracy: 0.9941 - val_loss: 0.1566\n",
      "Epoch 4/10\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m718s\u001b[0m 4s/step - accuracy: 0.9900 - loss: 0.0586 - val_accuracy: 0.9883 - val_loss: 0.0675\n",
      "Epoch 5/10\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m706s\u001b[0m 3s/step - accuracy: 0.9932 - loss: 0.0267 - val_accuracy: 0.9951 - val_loss: 0.0151\n",
      "Epoch 6/10\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 3s/step - accuracy: 0.9967 - loss: 0.0114 - val_accuracy: 0.9981 - val_loss: 0.0132\n",
      "Epoch 7/10\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 3s/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.9975 - val_loss: 0.0077\n",
      "Epoch 8/10\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m717s\u001b[0m 4s/step - accuracy: 0.9979 - loss: 0.0066 - val_accuracy: 0.9988 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 4s/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9981 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m719s\u001b[0m 4s/step - accuracy: 0.9982 - loss: 0.0050 - val_accuracy: 0.9951 - val_loss: 0.0147\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential  # Importing Sequential to build the model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense  # Importing necessary layers for the CNN\n",
    "from tensorflow.keras.utils import to_categorical  # Importing utility for converting labels to categorical format\n",
    "\n",
    "# Set the number of threads used for intra-op parallelism (within individual operations)\n",
    "# tf.config.threading.set_intra_op_parallelism_threads(5)\n",
    "\n",
    "# # Set the number of threads used for inter-op parallelism (between operations)\n",
    "# tf.config.threading.set_inter_op_parallelism_threads(5)\n",
    "\n",
    "# Convert labels to categorical format for training\n",
    "train_labels_cat = to_categorical(train_labels)\n",
    "val_labels_cat = to_categorical(val_labels)\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(512, 512, 3)),  # Convolutional layer + ReLU activation\n",
    "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
    "    Conv2D(32, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
    "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
    "    Conv2D(64, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
    "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
    "    Conv2D(128, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
    "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
    "    GlobalAveragePooling2D(),  # Global average pooling layer\n",
    "    Dense(5, activation='softmax')  # Output layer with 5 neurons (one for each class) + Softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model with appropriate loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Model defined and compiled successfully.\")\n",
    "\n",
    "# Train the model on the training data\n",
    "history = model.fit(\n",
    "    train_images, train_labels_cat,\n",
    "    epochs=10,  # Number of epochs\n",
    "    batch_size=64,  # Batch size\n",
    "    validation_data=(val_images, val_labels_cat)  # Validation data\n",
    ")\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde9d935-fda3-4ea3-8b33-4d5bd7cefc3a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e81814-27e8-4dbd-b73e-5976943b569a",
   "metadata": {},
   "source": [
    "### Perfomrmance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60197923-31a0-4a96-a83c-d373aa9abc3c",
   "metadata": {},
   "source": [
    "- Confusion Matrix: Provides a visual representation of the model’s performance across all classes, showing the number of correct and incorrect predictions for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad47117-cced-4a13-a4bb-a84b323a792c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 32/102\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 451ms/step"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report  # Importing necessary metrics for evaluation\n",
    "import matplotlib.pyplot as plt  # Importing Matplotlib for visualization\n",
    "import seaborn as sns  # Importing Seaborn for better visualizations\n",
    "\n",
    "# Predict the classes of the validation set\n",
    "val_predictions = model.predict(val_images)\n",
    "val_pred_classes = np.argmax(val_predictions, axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(val_labels, val_pred_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23981f2b-0f68-4559-9606-b2ed0d6d8f88",
   "metadata": {},
   "source": [
    "- Classification Report: Shows precision, recall, and F1-score for each class, giving a more detailed evaluation of model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181568a-2174-4e52-98dd-a9daa01ceb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "class_report = classification_report(val_labels, val_pred_classes, target_names=label_mapping.keys())\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d8d2f-4c53-4b04-aa12-ab9d6efe8b89",
   "metadata": {},
   "source": [
    "Measure Inference Time and Resource Usage:\n",
    "- Time Measurement: We use the time module to record the start and end times to calculate how long the model takes to make predictions.\n",
    "- Resource Monitoring: psutil is used to monitor CPU and memory usage before and after inference to simulate a production environment scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13623260-cb78-4955-992d-2685a750c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Importing time module to measure inference time\n",
    "import psutil  # Importing psutil for resource usage monitoring\n",
    "\n",
    "# Assuming train_images_flattened and train_labels are prepared and model is already trained\n",
    "\n",
    "# Function to measure inference time and resource usage for any model\n",
    "def measure_inference_performance(model, data, batch_size=64):\n",
    "    start_time = time.time()  # Record the start time\n",
    "    process = psutil.Process()  # Get current process information\n",
    "\n",
    "    # Initialize variables to track CPU and memory usage\n",
    "    cpu_usages = []\n",
    "    max_memory_usage = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "    # Perform predictions in batches\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch_data = data[i:i + batch_size]\n",
    "        _ = model.predict(batch_data)\n",
    "\n",
    "        # Record CPU and memory usage after each batch\n",
    "        cpu_usages.append(process.cpu_percent(interval=None))\n",
    "        current_memory_usage = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "        max_memory_usage = max(max_memory_usage, current_memory_usage)\n",
    "\n",
    "    end_time = time.time()  # Record the end time\n",
    "    inference_time = end_time - start_time  # Calculate total inference time\n",
    "    average_cpu_usage = sum(cpu_usages) / len(cpu_usages)  # Calculate average CPU usage\n",
    "\n",
    "    print(f\"Inference Time: {inference_time:.4f} seconds\")\n",
    "    print(f\"Average CPU Usage: {average_cpu_usage:.2f}%\")\n",
    "    print(f\"Maximum Memory Usage: {max_memory_usage:.2f} MB\")\n",
    "\n",
    "# Measure inference performance\n",
    "measure_inference_performance(model, val_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52eadc-b47b-4838-80bd-e1678910f92a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df845c9a-81f5-4174-8cda-1839a27b2aeb",
   "metadata": {},
   "source": [
    "Questions or Suggestions:\n",
    "\n",
    "- How can we develop a performance evaluation that fairly measures different pipelines? Should the evaluation include the full pre-processing pipeline or focus solely on the trained model?\n",
    "- Should we convert the problem into a binary classification task, or retain the current structure with five classes?\n",
    "- I am considering not including the full CNN model above, as it requires a significant amount of training time. However, I plan to provide the results in some form so that participants can make comparisons.\n",
    "- We need a single accuracy metric to simplify the evaluation process.\n",
    "- How/where should we store the data?\n",
    "-  It’s essential that no one has access to the testing data, as it will be secured exclusively for the final evaluation (After the hackathons).\n",
    "-  We need the paper to be online soon (before the trainers hack if possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ddbce-5789-4d82-88d7-5578e891a475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CubeHackKer",
   "language": "python",
   "name": "cubehackker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
